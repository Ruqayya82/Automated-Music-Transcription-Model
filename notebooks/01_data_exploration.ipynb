{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TranscribeAI - Data Exploration\n",
    "\n",
    "This notebook explores audio data and demonstrates basic audio processing techniques used in the TranscribeAI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from audio_processing import AudioLoader, FeatureExtractor, PitchDetector, OnsetDetector\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize audio loader\n",
    "audio_loader = AudioLoader(sample_rate=22050)\n",
    "\n",
    "# Load audio file (replace with your audio file path)\n",
    "audio_path = '../data/raw/sample.wav'\n",
    "audio, sr = audio_loader.load_audio(audio_path)\n",
    "\n",
    "print(f\"Audio shape: {audio.shape}\")\n",
    "print(f\"Sample rate: {sr} Hz\")\n",
    "print(f\"Duration: {len(audio)/sr:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "librosa.display.waveshow(audio, sr=sr)\n",
    "plt.title('Audio Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature extractor\n",
    "feature_extractor = FeatureExtractor(sample_rate=sr)\n",
    "\n",
    "# Extract mel spectrogram\n",
    "mel_spec = feature_extractor.extract_mel_spectrogram(audio)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(mel_spec, sr=sr, hop_length=512, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pitch Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pitch detector\n",
    "pitch_detector = PitchDetector(sample_rate=sr)\n",
    "\n",
    "# Extract pitch contour\n",
    "pitch_info = pitch_detector.extract_pitch_contour(audio, smooth=True)\n",
    "\n",
    "# Visualize pitch contour\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(pitch_info['times'], pitch_info['f0'], label='Pitch (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Pitch Contour')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get pitch statistics\n",
    "stats = pitch_detector.get_pitch_statistics(pitch_info['f0'])\n",
    "print(\"\\nPitch Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Onset Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize onset detector\n",
    "onset_detector = OnsetDetector(sample_rate=sr)\n",
    "\n",
    "# Detect onsets\n",
    "onsets = onset_detector.detect_onsets(audio, units='time')\n",
    "\n",
    "print(f\"Detected {len(onsets)} onsets\")\n",
    "print(f\"Onset times: {onsets[:10]}...\")  # Show first 10\n",
    "\n",
    "# Visualize onsets on waveform\n",
    "plt.figure(figsize=(14, 4))\n",
    "librosa.display.waveshow(audio, sr=sr, alpha=0.6)\n",
    "plt.vlines(onsets, -1, 1, color='r', alpha=0.8, linestyle='--', label='Onsets')\n",
    "plt.title('Audio Waveform with Detected Onsets')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get onset statistics\n",
    "duration = len(audio) / sr\n",
    "onset_stats = onset_detector.get_onset_statistics(onsets, duration)\n",
    "print(\"\\nOnset Statistics:\")\n",
    "for key, value in onset_stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combined Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Waveform with onsets\n",
    "librosa.display.waveshow(audio, sr=sr, ax=axes[0], alpha=0.6)\n",
    "axes[0].vlines(onsets, -1, 1, color='r', alpha=0.8, linestyle='--')\n",
    "axes[0].set_title('Waveform with Onsets')\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "\n",
    "# Mel spectrogram\n",
    "img = librosa.display.specshow(mel_spec, sr=sr, hop_length=512, \n",
    "                                x_axis='time', y_axis='mel', ax=axes[1])\n",
    "axes[1].set_title('Mel Spectrogram')\n",
    "plt.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "\n",
    "# Pitch contour\n",
    "axes[2].plot(pitch_info['times'], pitch_info['f0'], color='blue', linewidth=2)\n",
    "axes[2].set_title('Pitch Contour')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "axes[2].set_ylabel('Frequency (Hz)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convert to MIDI Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize pitch to MIDI notes\n",
    "midi_notes = pitch_detector.quantize_pitch(pitch_info['midi_notes'])\n",
    "\n",
    "# Filter out NaN values\n",
    "valid_mask = ~np.isnan(midi_notes)\n",
    "valid_midi = midi_notes[valid_mask]\n",
    "\n",
    "print(f\"Detected MIDI note range: {int(np.min(valid_midi))} to {int(np.max(valid_midi))}\")\n",
    "print(f\"Note range: {pitch_detector.midi_to_note_name(np.min(valid_midi))} to {pitch_detector.midi_to_note_name(np.max(valid_midi))}\")\n",
    "\n",
    "# Plot MIDI notes histogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(valid_midi, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('MIDI Note Number')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Detected MIDI Notes')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and visualizing audio data\n",
    "2. Extracting audio features (mel spectrogram)\n",
    "3. Detecting pitch using pYIN algorithm\n",
    "4. Detecting note onsets\n",
    "5. Converting pitch to MIDI notes\n",
    "\n",
    "These techniques form the foundation of the TranscribeAI transcription pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
