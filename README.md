# ğŸµ TranscribeAI

An AI-powered music transcription system that converts audio recordings of piano and guitar music into MIDI files and MusicXML notation.

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8 or higher** (Python 3.10+ recommended)
- **pip** package manager
- **FFmpeg** (required for audio processing)

### System Dependencies

#### Install FFmpeg:

**Windows:**
```bash
# Using Chocolatey
choco install ffmpeg

# OR download from https://ffmpeg.org/download.html
```

**macOS:**
```bash
brew install ffmpeg
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd TranscribeAI
```

2. Install Python dependencies:
```bash
pip install -r requirements.txt
```
   *Note: This will install all required packages including Flask, librosa, PyTorch, mido, music21, and more.*

3. **(Optional)** Verify all dependencies are installed:
```bash
python check_dependencies.py
```
   *This script will check if all required packages are properly installed and report any missing dependencies.*

4. Run the application:
```bash
python run.py
```

5. Open your browser to: **http://localhost:5000**


### Troubleshooting Installation

If you encounter "ModuleNotFoundError" after installation:

1. Run the dependency checker to identify missing packages:
   ```bash
   python check_dependencies.py
   ```

2. Install any missing packages individually:
   ```bash
   pip install <package-name>
   ```

3. Ensure FFmpeg is installed (required for audio processing)

4. If issues persist, try upgrading pip:
   ```bash
   python -m pip install --upgrade pip
   pip install -r requirements.txt --force-reinstall
   ```

## ğŸ“ Project Structure

```
TranscribeAI/
â”‚
â”œâ”€â”€ run.py                          # Main application entry point - RUN THIS FILE
â”œâ”€â”€ config.yaml                     # Configuration settings
â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚
â”œâ”€â”€ data/                           # Audio data directory
â”‚   â”œâ”€â”€ PianoMusic/                 # Piano audio samples (.mp3)
â”‚   â””â”€â”€ GuitarMusic/                # Guitar audio samples (.mp3)
â”‚
â”œâ”€â”€ src/                            # Backend source code
â”‚   â”œâ”€â”€ audio_processing/           # Audio analysis modules
â”‚   â”‚   â”œâ”€â”€ audio_loader.py         # Load and preprocess audio
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py    # Extract audio features
â”‚   â”‚   â”œâ”€â”€ pitch_detector.py       # Detect pitch
â”‚   â”‚   â””â”€â”€ onset_detector.py       # Detect note onsets
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     # Transcription models
â”‚   â”‚   â”œâ”€â”€ transcription_model.py  # Main transcription interface
â”‚   â”‚   â”œâ”€â”€ pitch_onset_cnn.py      # Optional ML model (not required)
â”‚   â”‚   â””â”€â”€ model_trainer.py        # Model training utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ midi_generation/            # MIDI file generation
â”‚   â”‚   â”œâ”€â”€ midi_creator.py         # Create MIDI files
â”‚   â”‚   â””â”€â”€ note_processor.py       # Process detected notes
â”‚   â”‚
â”‚   â”œâ”€â”€ musicxml_conversion/        # MusicXML generation
â”‚   â”‚   â””â”€â”€ musicxml_generator.py   # Convert MIDI to MusicXML
â”‚   â”‚
â”‚   â””â”€â”€ web_app/                    # Frontend (Flask web application)
â”‚       â”œâ”€â”€ app.py                  # Flask application
â”‚       â”œâ”€â”€ templates/              # HTML templates
â”‚       â”‚   â””â”€â”€ index.html          # Main web interface
â”‚       â””â”€â”€ static/                 # Static assets
â”‚           â”œâ”€â”€ css/
â”‚           â”‚   â””â”€â”€ style.css       # Dark mode styling
â”‚           â””â”€â”€ js/
â”‚               â””â”€â”€ app.js          # Frontend JavaScript
â”‚
â”œâ”€â”€ uploads/                        # Uploaded audio files (auto-created)
â”œâ”€â”€ outputs/                        # Generated MIDI/MusicXML files (auto-created)
â”‚
â”œâ”€â”€ examples/                       # Usage examples
â”‚   â””â”€â”€ transcribe_example.py       # Example transcription script
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks for exploration
â”‚   â””â”€â”€ 01_data_exploration.ipynb
â”‚
â”œâ”€â”€ figma_designs/                  # UI design files
â”‚   â”œâ”€â”€ wireframe.html
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ logo/                           # Project branding
    â””â”€â”€ TransribeAI logo.png
```

## ğŸ¯ How It Works

TranscribeAI uses **traditional signal processing methods** by default (no ML model required):

1. **Audio Upload** - Upload piano or guitar audio files (.mp3, .wav, .ogg, .flac)
2. **Pitch Detection** - Analyzes the audio to detect musical pitches
3. **Onset Detection** - Identifies when notes start
4. **Note Extraction** - Combines pitch and onset information to extract individual notes
5. **MIDI Generation** - Creates a MIDI file from detected notes
6. **MusicXML Export** - Converts MIDI to MusicXML for use in notation software

## ğŸ¨ Features

- **Dark Mode UI** - Modern, eye-friendly dark theme with proper contrast
- **Drag & Drop Upload** - Easy file uploading interface
- **Real-time Progress** - Visual feedback during transcription
- **Multiple Export Formats** - MIDI and MusicXML output
- **No ML Model Required** - Works out-of-the-box with signal processing
- **Clean Project Structure** - Clearly organized codebase

## ğŸ¼ Supported Audio Formats

- MP3 (.mp3)
- WAV (.wav)
- OGG (.ogg)
- FLAC (.flac)

## ğŸ”§ Configuration

Edit `config.yaml` to customize:
- Audio processing parameters
- MIDI settings (tempo, velocity)
- Upload/output folders
- File size limits

## ğŸ“Š Testing with Sample Data

The `data/` folder contains sample piano and guitar music files you can use to test the system:
- `data/PianoMusic/` - 10 piano audio samples
- `data/GuitarMusic/` - 10 guitar audio samples

## ğŸ› ï¸ Technical Stack

- **Backend**: Python, Flask
- **Audio Processing**: librosa, numpy, scipy
- **MIDI Generation**: mido
- **MusicXML**: music21
- **Frontend**: HTML5, CSS3, JavaScript
- **ML Framework** (optional): PyTorch

## ğŸ“ Usage Example

### Using the Web Interface
1. Run `python run.py`
2. Open http://localhost:5000 in your browser
3. Upload an audio file
4. Click "Transcribe"
5. Download MIDI and/or MusicXML files

### Using Python API
```python
from src.models.transcription_model import TranscriptionModel
import yaml

# Load config
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Initialize model
model = TranscriptionModel(config, device='cpu')

# Transcribe audio
notes, metadata = model.transcribe('data/PianoMusic/piano1.mp3')

print(f"Detected {len(notes)} notes")
```

## ğŸš§ Development

### Adding New Features
- Audio processing: Add to `src/audio_processing/`
- Models: Add to `src/models/`
- Web interface: Modify `src/web_app/`

### Running Tests
```bash
# In the Future: We Add test commands here
```


## ğŸ‘¥ Contributors

Ruqayya Mustafa

Yuki Li

Patience IZERE

Md Mazharul Islam 

## ğŸ™ Acknowledgments

Built with librosa, mido, music21, Flask, and PyTorch.
