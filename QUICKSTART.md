# TranscribeAI - Quick Start Guide

Welcome to TranscribeAI! This guide will help you get started quickly with the music transcription system.

## ğŸš€ Quick Setup

### 1. Install Dependencies

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Run the Web Application

```bash
# Start the Flask web server
python src/web_app/app.py
```

Then open your browser to `http://localhost:5000`

## ğŸ“ Usage Examples

### Web Interface (Recommended for Beginners)

1. Open `http://localhost:5000` in your browser
2. Upload an audio file (WAV, MP3, FLAC, OGG, M4A)
3. Click "Transcribe Audio"
4. Download the generated MIDI and MusicXML files

### Command Line

```bash
# Using the example script
cd examples
python transcribe_example.py
```

### Jupyter Notebooks

```bash
# Start Jupyter
jupyter notebook

# Open notebooks/01_data_exploration.ipynb
```

## ğŸ“ Project Structure

```
TranscribeAI/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ audio_processing/   # Audio analysis
â”‚   â”œâ”€â”€ models/             # ML models
â”‚   â”œâ”€â”€ midi_generation/    # MIDI creation
â”‚   â”œâ”€â”€ musicxml_conversion/# Sheet music
â”‚   â””â”€â”€ web_app/            # Web interface
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”œâ”€â”€ examples/               # Example scripts
â”œâ”€â”€ data/                   # Audio data
â”œâ”€â”€ outputs/                # Generated files
â”œâ”€â”€ figma_designs/          # UI wireframes
â””â”€â”€ logo/                   # Brand assets
```

## ğŸµ Supported Audio Formats

- WAV (recommended)
- MP3
- FLAC
- OGG
- M4A

**Best Results**: Monophonic audio (single instrument, no percussion)

## ğŸ”§ Configuration

Edit `config.yaml` to customize:
- Audio processing settings
- Model parameters
- MIDI generation options
- MusicXML formatting

## ğŸ“Š Features

### Audio Processing
- âœ… Pitch detection (pYIN algorithm)
- âœ… Onset detection
- âœ… Feature extraction (mel spectrogram, MFCC, etc.)

### Transcription Methods
- **Traditional**: Signal processing (fast, no training required)
- **ML Model**: CNN-LSTM network (more accurate, requires training)

### Output Formats
- **MIDI**: Standard MIDI file format
- **MusicXML**: Sheet music format (open in MuseScore, Finale, etc.)

## ğŸ¯ Workflow

1. **Upload Audio** â†’ Choose your audio file
2. **Select Method** â†’ ML Model or Traditional
3. **Transcribe** â†’ Process the audio
4. **Download** â†’ Get MIDI and MusicXML files
5. **View** â†’ Open in your favorite music software

## ğŸ’¡ Tips for Best Results

1. **Audio Quality**: Use high-quality recordings
2. **Monophonic**: Single instrument works best
3. **Clean Audio**: Minimize background noise
4. **File Size**: Keep under 10MB for web upload
5. **Format**: WAV or FLAC for best quality

## ğŸ” Troubleshooting

### "No module named 'src'"
Make sure you're running from the project root directory.

### "MIDI file not created"
Check that the audio file contains detectable notes.

### Web app not starting
Ensure port 5000 is not in use:
```bash
# Windows
netstat -ano | findstr :5000

# macOS/Linux
lsof -i :5000
```

## ğŸ“š Additional Resources

- **Documentation**: See README.md
- **Examples**: Check the `examples/` directory
- **Notebooks**: Explore `notebooks/` for tutorials
- **Figma**: UI/UX designs in `figma_designs/`

## ğŸ› ï¸ Development

### Running Tests
```bash
pytest tests/
```

### Code Formatting
```bash
black src/
flake8 src/
```

### Training ML Model
```bash
python src/train.py --config config.yaml
```

## ğŸŒ Web API Endpoints

- `GET /` - Main interface
- `POST /api/upload` - Upload audio file
- `POST /api/transcribe` - Transcribe audio
- `GET /api/download/<filename>` - Download results
- `GET /api/status` - Check API status

## ğŸ“§ Support

For issues or questions:
- Check the README.md
- Review example scripts
- Explore Jupyter notebooks

## ğŸ‰ Next Steps

1. Try transcribing your first audio file
2. Experiment with different settings in `config.yaml`
3. Explore the Jupyter notebooks for deeper understanding
4. Train your own ML model with custom data

Happy transcribing! ğŸµ
